{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da46adae",
   "metadata": {},
   "source": [
    "Defino los mapas de los conjuntos y los alias para los 4 algoritmos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69527ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import joblib  # Para guardar los modelos entrenados\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "\n",
    "# Definimos los métodos (algoritmos) que vamos a usar\n",
    "# Es importante activar probability=True en SVM para el futuro cálculo de Ensembles\n",
    "modelos_config = {\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors=3), # Puedes ajustar n_neighbors\n",
    "    \"svm\": SVC(probability=True, random_state=42),\n",
    "    \"nb\": GaussianNB(),\n",
    "    \"rf\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Mapeo de los nombres de dataset a tus carpetas y sufijos de archivo\n",
    "# Según lo que generamos en la práctica anterior:\n",
    "datasets_map = {\n",
    "    # Datos Originales\n",
    "    \"original\": {\"folder\": \"Original\", \"suffix\": \"\"},\n",
    "    \"originalPCA95\": {\"folder\": \"Original\", \"suffix\": \"_pca95\"},\n",
    "    \"originalPCA80\": {\"folder\": \"Original\", \"suffix\": \"_pca80\"},\n",
    "    \n",
    "    # Datos Estandarizados\n",
    "    \"estandarizado\": {\"folder\": \"Estandarizado\", \"suffix\": \"\"},\n",
    "    \"estandarizadoPCA95\": {\"folder\": \"Estandarizado\", \"suffix\": \"_pca95\"},\n",
    "    \"estandarizadoPCA80\": {\"folder\": \"Estandarizado\", \"suffix\": \"_pca80\"},\n",
    "    \n",
    "    # Datos Normalizados\n",
    "    \"normalizado\": {\"folder\": \"Normalizado\", \"suffix\": \"\"},\n",
    "    \"normalizadoPCA95\": {\"folder\": \"Normalizado\", \"suffix\": \"_pca95\"},\n",
    "    \"normalizadoPCA80\": {\"folder\": \"Normalizado\", \"suffix\": \"_pca80\"},\n",
    "}\n",
    "\n",
    "# Carpeta donde guardaremos los modelos entrenados\n",
    "models_output_folder = \"models\"\n",
    "if not os.path.exists(models_output_folder):\n",
    "    os.makedirs(models_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b0b8a3",
   "metadata": {},
   "source": [
    "Siguiente función:\n",
    "\n",
    "\n",
    "-Construye la ruta del archivo training correcto basándose en el mapa que acabamos de definir arriba\n",
    "\n",
    "-Carga los datos\n",
    "\n",
    "-Separa lo de las características (X) y las etiquetas (y)\n",
    "\n",
    "-Entrena el modelo que le entra\n",
    "\n",
    "-Guarda el modelo en la carpeta models con su nombre ej estructura  --->  model_3_normalizadoPCA95_knn.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75221ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(fold, method, dataset_name):\n",
    "    \"\"\"\n",
    "    Entrena un modelo específico para una iteración y dataset dados, y lo guarda en disco.\n",
    "    \n",
    "    Args:\n",
    "        fold (int): Número de iteración (1 a 5).\n",
    "        method (str): Nombre del algoritmo ('knn', 'svm', 'nb', 'rf').\n",
    "        dataset_name (str): Clave del dataset (ej: 'original', 'normalizadoPCA80').\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Identificar archivo de datos\n",
    "    info = datasets_map[dataset_name]\n",
    "    filename = f\"training{fold}{info['suffix']}.csv\"\n",
    "    filepath = os.path.join(info['folder'], filename)\n",
    "    \n",
    "    # Verificar si existe\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Error: No se encuentra {filepath}\")\n",
    "        return\n",
    "\n",
    "    # 2. Cargar datos\n",
    "    # Asumimos que la última columna es la etiqueta (clase)\n",
    "    data = pd.read_csv(filepath, header=None)\n",
    "    X_train = data.iloc[:, :-1].values\n",
    "    y_train = data.iloc[:, -1].values.ravel() # ravel() para asegurar que sea un vector 1D\n",
    "\n",
    "    # 3. Inicializar el modelo\n",
    "    if method not in modelos_config:\n",
    "        print(f\"Método {method} no reconocido.\")\n",
    "        return\n",
    "    \n",
    "    # Usamos 'clone' o creamos una nueva instancia para asegurar que está limpio\n",
    "    # Aquí simplemente tomamos la configuración base y la ajustamos si fuera necesario\n",
    "    # Para simplificar, usamos la instancia del diccionario (se re-entrena con fit)\n",
    "    clf = modelos_config[method]\n",
    "    \n",
    "    # 4. Entrenar\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # 5. Guardar el modelo\n",
    "    # Nombre formato: model_{fold}_{dataset}_{method}.pkl\n",
    "    model_filename = f\"model_{fold}_{dataset_name}_{method}.pkl\"\n",
    "    model_path = os.path.join(models_output_folder, model_filename)\n",
    "    \n",
    "    joblib.dump(clf, model_path)\n",
    "    # print(f\" Modelo guardado: {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
